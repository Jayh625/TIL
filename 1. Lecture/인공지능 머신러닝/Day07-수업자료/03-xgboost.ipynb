{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle 의 titanic dataset 을 이용하여 탑승자의 생존여부를 판별하는 Logistic Regression 모델을 학습합니다. 이 데이터에 대한 자세한 설명은 아래의 링크를 참고하세요. 우리는 미리 다운로드한 데이터를 로딩합니다.\n",
    "\n",
    "https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T05:48:29.002613Z",
     "start_time": "2022-06-03T05:48:25.890244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = './data/titanic_train.csv'\n",
    "titanic = pd.read_csv(data_path, index_col='PassengerId')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 데이터를 행렬 형태로 변환하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(['Name', 'Ticket'], axis=1, inplace=True)\n",
    "embark_dummy = pd.get_dummies(titanic['Embarked'], prefix='port')\n",
    "\n",
    "age_group = titanic['Age'] < 20\n",
    "age_group[age_group] = 'child'\n",
    "age_group[titanic['Age'] >= 20] = 'adult'\n",
    "age_group[titanic['Age'].isnull()] = 'unknown'\n",
    "age_group.name = 'AgeGroup'\n",
    "age_dummy = pd.get_dummies(age_group, prefix='Age')\n",
    "\n",
    "pclass_dummy = pd.get_dummies(titanic['Pclass'], prefix='Pclass')\n",
    "titanic['Sex'] = titanic['Sex'].map({'female':1, 'male':0})\n",
    "\n",
    "titanic = pd.concat([titanic, pclass_dummy, embark_dummy, age_dummy], axis=1)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 학습용 데이터와 테스트용 데이터를 4:1 로 구분합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def make_train_data(input_names, output_name):\n",
    "    X = titanic[input_names].to_numpy()\n",
    "    y = titanic[output_name].to_numpy()\n",
    "    print(f'shape of X = {X.shape}')\n",
    "    print(f'shape of y = {y.shape}')\n",
    "    return X, y\n",
    "\n",
    "input_names = 'Pclass_1 Pclass_2 Pclass_3 Sex SibSp Parch Fare port_C port_Q port_S Age_adult Age_child Age_unknown'.split()\n",
    "output_name = 'Survived'\n",
    "\n",
    "X, y = make_train_data(input_names, output_name)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "def check_accuracy(y_answer, y_pred):\n",
    "    accuracy = (y_answer == y_pred).sum() / y_pred.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "accuracy_lr = check_accuracy(y_pred_lr, y_test)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 XGBoost 를 이용하여 동일한 데이터를 구분하는 판별기를 학습해 봅니다. XGBoost 의 버전은 0.90 또는 1.6.1 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import xgboost as xgb\n",
    "\n",
    "print(f'xgboost=={xgb.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost 역시 scikit-learn 처럼 손쉽게 학습을 할 수 있습니다. 우선 boosting trees 의 개수를 10 개로 적게 설정해봅니다. 정확도가 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators = 10,\n",
    "    max_depth = 4,\n",
    "    booster = 'gbtree',\n",
    "    eta = 0.3,\n",
    "    gamma = 0,    \n",
    "    silent = 0,\n",
    "    objective = 'binary:logistic',\n",
    "    nthread = 4,\n",
    "    base_score = 0.5,    \n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "check_accuracy(y_pred_xgb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost 는 각 base estimators 가 순차적으로 정의/학습되기 때문에 우선 최대한 과적합을 한 뒤에, 예측 시 사용하는 base estimators 의 개수를 제한해도 됩니다. `ntree_limit` 는 이에 대한 값입니다. 우리는 500 개의 boosting trees 를 이용하여 우선 과적합을 한 뒤, 10 부터 500 까지 10 단위로 trees 의 개수를 조절하며 예측 성능의 정확도를 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "        n_estimators = 500,\n",
    "        max_depth = 4,\n",
    "        booster = 'gbtree',\n",
    "        eta = 0.3,\n",
    "        gamma = 0,    \n",
    "        silent = 0,\n",
    "        objective = 'binary:logistic',\n",
    "        nthread = 4,\n",
    "        base_score = 0.5,    \n",
    "    )\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# (n_estimators, train accuracy, test accuracy)\n",
    "performances = []\n",
    "for n_estimators in range(10, 501, 10):\n",
    "    y_pred_train_xgb = xgb_clf.predict(X_train, ntree_limit=n_estimators)\n",
    "    y_pred_test_xgb = xgb_clf.predict(X_test, ntree_limit=n_estimators)\n",
    "    train_accuracy = check_accuracy(y_pred_train_xgb, y_train)\n",
    "    test_accuracy = check_accuracy(y_pred_test_xgb, y_test)\n",
    "    performances.append((n_estimators, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees 의 개수와 정확도의 플랏을 그려보면 학습 데이터에 대한 정확도는 계속하여 올라가지만 테스트 데이터에 대한 정확도는 0.82 정도까지 올라간 뒤 오히려 감소합니다. 이는 학습데이터의 개수는 작은데 (트레이닝 데이터 약 680 개), trees 의 개수가 지나치게 많기 때문에 과적합이 발생하였기 때문입니다.\n",
    "\n",
    "사실 XGBoost 는 titanic 처럼 작은 데이터에 적합한 알고리즘이 아닙니다. 매우 큰 용량의 데이터에서 훨씬 잘 작동하는 알고리즘이지만, 우리는 사용법에 대해서만 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook, save\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "n_estimators, train_accuracy, test_accuracy = zip(*performances)\n",
    "p = figure(plot_width=800, plot_height=400, title='Accuracy by n_estimators (XGB)')\n",
    "p.line(n_estimators, train_accuracy, line_width=2, line_color='orange', legend_label='Train')\n",
    "p.line(n_estimators, test_accuracy, line_width=2, line_color='blue', legend_label='Test')\n",
    "p.xaxis.axis_label = 'n estimators'\n",
    "p.yaxis.axis_label = 'accuracy'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리그레션 모델을 이용하는 방법도 앞과 동일합니다. 단지 loss function 인 `objective` 를 회귀모델용으로 바꿔줘야 합니다.\n",
    "아래 코드는 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(\n",
    "        n_estimators = 500,\n",
    "        max_depth = 4,\n",
    "        booster = 'gbtree',\n",
    "        eta = 0.3,\n",
    "        gamma = 0,    \n",
    "        silent = 0,\n",
    "        objective = 'reg:squarederror',\n",
    "        nthread = 4,\n",
    "        base_score = 0.5,    \n",
    "    )\n",
    "xgb_reg = xgb_reg.fit(x.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
